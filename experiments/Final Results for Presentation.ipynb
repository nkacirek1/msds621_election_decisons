{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    \"\"\"\n",
    "    Uses LabelEncoder to encode disrecete values\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            le = LabelEncoder()\n",
    "            df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data_f):\n",
    "    \"\"\"\n",
    "    Oversamples the highly contested races\n",
    "    \"\"\"\n",
    "    df_contested = data_f[data_f.TIGHT_RACE == True].reset_index(drop=True)\n",
    "    df_not_contested = data_f[data_f.TIGHT_RACE == False].reset_index(drop=True)\n",
    "    sample = np.random.choice(range(df_contested.shape[0]), size=df_not_contested.shape[0], replace=True)\n",
    "    df_contested_bootstrapped = df_contested.iloc[sample].reset_index(drop=True)\n",
    "    frames = [df_not_contested, df_contested_bootstrapped]\n",
    "    df_new = pd.concat(frames)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **r100** : 100% of precincts reporting\n",
    "- **r5**: 5% of precincts reporting\n",
    "- **_3**: 3 strata\n",
    "- **_6**: 6 strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 % reporting\n",
    "r100_3 = pd.read_csv(\"../full_data/final.csv\")\n",
    "r100_6 = pd.read_csv(\"../full_data/full_final.csv\")\n",
    "\n",
    "# 90 % reporting\n",
    "r90_3 = pd.read_csv(\"../partial_data/90/90_reporting.csv\")\n",
    "r90_6 = pd.read_csv(\"../partial_data/90/90_reporting_6.csv\")\n",
    "\n",
    "# 75 % reporting\n",
    "r75_3 = pd.read_csv(\"../partial_data/75/75_reporting.csv\")\n",
    "r75_6 = pd.read_csv(\"../partial_data/75/75_reporting_6.csv\")\n",
    "\n",
    "# 50 % reporting\n",
    "r50_3 = pd.read_csv(\"../partial_data/50/50_reporting.csv\")\n",
    "r50_6 = pd.read_csv(\"../partial_data/50/50_reporting_6.csv\")\n",
    "\n",
    "# 25 % reporting\n",
    "r25_3 = pd.read_csv(\"../partial_data/25/25_reporting.csv\")\n",
    "r25_6 = pd.read_csv(\"../partial_data/25/25_reporting_6.csv\")\n",
    "\n",
    "# 15 % reporting\n",
    "r15_3 = pd.read_csv(\"../partial_data/15/15_reporting.csv\")\n",
    "r15_6 = pd.read_csv(\"../partial_data/15/15_reporting_6.csv\")\n",
    "\n",
    "# 10 % reporting\n",
    "r10_3 = pd.read_csv(\"../partial_data/10/10_reporting.csv\")\n",
    "r10_6 = pd.read_csv(\"../partial_data/10/10_reporting_6.csv\")\n",
    "\n",
    "# 5 % reporting\n",
    "r5_3 = pd.read_csv(\"../partial_data/5/5_reporting.csv\")\n",
    "r5_6 = pd.read_csv(\"../partial_data/5/5_reporting_6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all of the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [r100_3, r100_6, r90_3, r90_6, r75_3, r75_6, r50_3, r50_6, \n",
    "               r25_3, r25_6, r15_3, r15_6, r10_3, r10_6, r5_3, r5_6]\n",
    "\n",
    "for d in data_frames:\n",
    "    d = encode(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize StratifiedKFold's to be set to 5 spilts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Six Strata\n",
    "\n",
    "Compare a Decision Tree with Correlations and 6 Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6677663734115346 0.5952380952380952\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6.drop(columns=['WINNER'])\n",
    "y_ = r100_6.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 6 strata but no correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r100_6_nc = r100_6[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                         'S4_DEM_RATIO','S5_DEM_RATIO', 'S6_DEM_RATIO',\n",
    "                         'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                         'S4_REP_RATIO', 'S5_REP_RATIO', 'S6_REP_RATIO',\n",
    "                         'TIGHT_RACE', 'WINNER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8032644998370805 0.7797619047619048\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 strata with correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6781830400782013 0.6428571428571428\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3.drop(columns=['WINNER'])\n",
    "y_ = r100_3.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 strata no correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r100_3_nc = r100_3[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                    'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                    'TIGHT_RACE', 'WINNER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918601335940045 0.6845238095238094\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7286677256435321 0.7261904761904763\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=7)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(dt.score(X_test, y_test))\n",
    "    tight_from_test.append(dt.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413550830889539 0.6904761904761906\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=7)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(dt.score(X_test, y_test))\n",
    "    tight_from_test.append(dt.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8127341968067775 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(gbc.score(X_test, y_test))\n",
    "    tight_from_test.append(gbc.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7189027370478983 0.6904761904761906\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "    X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "    y_train = oversampled_df.WINNER\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, max_depth=6)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(gbc.score(X_test, y_test))\n",
    "    tight_from_test.append(gbc.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test With Fewer Precincts Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the winning model from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dfs = [r90_6, r75_6, r50_6, r25_6, r15_6, r10_6, r5_6]\n",
    "testing_nc_dfs = [df[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                         'S4_DEM_RATIO','S5_DEM_RATIO', 'S6_DEM_RATIO',\n",
    "                         'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                         'S4_REP_RATIO', 'S5_REP_RATIO', 'S6_REP_RATIO',\n",
    "                         'TIGHT_RACE', 'WINNER']] for df in testing_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents = [90, 75, 50, 25, 15, 10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(partial_reporting_df, perc):\n",
    "    scores = []\n",
    "    tight_from_test = []\n",
    "    p_scores = []\n",
    "    p_tight = []\n",
    "    \n",
    "    p_X = partial_reporting_df.drop(columns=['WINNER'])\n",
    "    p_y = partial_reporting_df.WINNER\n",
    "    p_tight_only = partial_reporting_df[partial_reporting_df.TIGHT_RACE]\n",
    "    p_tight_X = p_tight_only.drop(columns=['WINNER'])\n",
    "    p_tight_y = p_tight_only.WINNER\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "        X_test = X_.iloc[test_index]\n",
    "        y_test = y_.iloc[test_index]\n",
    "\n",
    "        oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "        X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "        y_train = oversampled_df.WINNER\n",
    "\n",
    "        rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(dt.score(X_test, y_test))\n",
    "        tight_from_test.append(dt.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "        p_scores.append(dt.score(p_X, p_y))\n",
    "        p_tight.append(dt.score(p_tight_X, p_tight_y))\n",
    "\n",
    "    print(perc, np.mean(scores), np.mean(tight_from_test), np.mean(p_scores), np.mean(p_tight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 0.8029488432714239 0.7321428571428571 0.8767123287671232 0.8392434988179668\n",
      "75 0.8227944770283481 0.875 0.867579908675799 0.8160919540229884\n",
      "50 0.7824311665037471 0.7321428571428571 0.8995433789954338 0.8039215686274509\n",
      "25 0.8039161779081133 0.8273809523809524 0.8606030647553139 0.7743055555555555\n",
      "15 0.7908927989573152 0.6845238095238094 0.8750761730652042 0.8341307814992026\n",
      "10 0.7823904366243076 0.8273809523809524 0.8538812785388128 0.7608695652173912\n",
      "5 0.7814434669273379 0.7321428571428572 0.8633377135348225 0.8082191780821918\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(percents)):\n",
    "    random_forest(testing_nc_dfs[i], percents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
