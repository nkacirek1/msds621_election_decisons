{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    \"\"\"\n",
    "    Uses LabelEncoder to encode disrecete values\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            le = LabelEncoder()\n",
    "            df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data_f):\n",
    "    \"\"\"\n",
    "    Oversamples the highly contested races\n",
    "    \"\"\"\n",
    "    df_contested = data_f[data_f.TIGHT_RACE == True].reset_index(drop=True)\n",
    "    df_not_contested = data_f[data_f.TIGHT_RACE == False].reset_index(drop=True)\n",
    "    sample = np.random.choice(range(df_contested.shape[0]), size=df_not_contested.shape[0], replace=True)\n",
    "    df_contested_bootstrapped = df_contested.iloc[sample].reset_index(drop=True)\n",
    "    frames = [df_not_contested, df_contested_bootstrapped]\n",
    "    df_new = pd.concat(frames)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tight_race_split(df, num_strata, include_corrs=True):\n",
    "    \"\"\"\n",
    "    Given a dataframe, grabs the races that are tight for testing\n",
    "    \"\"\"\n",
    "    \n",
    "    tight_only = df[df.TIGHT_RACE]\n",
    "    \n",
    "    if not include_corrs:\n",
    "        if num_strata == 3:\n",
    "            tight_X = tight_only[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO', \n",
    "                                      'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO', \n",
    "                                      'TIGHT_RACE']]\n",
    "\n",
    "        elif num_strata == 6:\n",
    "            tight_X = tight_only[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                                  'S4_DEM_RATIO','S5_DEM_RATIO', 'S6_DEM_RATIO',\n",
    "                                  'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                                  'S4_REP_RATIO', 'S5_REP_RATIO', 'S6_REP_RATIO',\n",
    "                                  'TIGHT_RACE']]\n",
    "    else:\n",
    "        tight_X = tight_only.drop(columns=['WINNER'])\n",
    "    \n",
    "    tight_y = tight_only.WINNER\n",
    "    \n",
    "    return tight_X, tight_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **r100** : 100% of precincts reporting\n",
    "- **r5**: 5% of precincts reporting\n",
    "- **_3**: 3 strata\n",
    "- **_6**: 6 strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 % reporting\n",
    "r100_3 = pd.read_csv(\"../full_data/final.csv\")\n",
    "r100_6 = pd.read_csv(\"../full_data/full_final.csv\")\n",
    "\n",
    "# 90 % reporting\n",
    "r90_3 = pd.read_csv(\"../partial_data/90/90_reporting.csv\")\n",
    "r90_6 = pd.read_csv(\"../partial_data/90/90_reporting_6.csv\")\n",
    "\n",
    "# 75 % reporting\n",
    "r75_3 = pd.read_csv(\"../partial_data/75/75_reporting.csv\")\n",
    "r75_6 = pd.read_csv(\"../partial_data/75/75_reporting_6.csv\")\n",
    "\n",
    "# 50 % reporting\n",
    "r50_3 = pd.read_csv(\"../partial_data/50/50_reporting.csv\")\n",
    "r50_6 = pd.read_csv(\"../partial_data/50/50_reporting_6.csv\")\n",
    "\n",
    "# 25 % reporting\n",
    "r25_3 = pd.read_csv(\"../partial_data/25/25_reporting.csv\")\n",
    "r25_6 = pd.read_csv(\"../partial_data/25/25_reporting_6.csv\")\n",
    "\n",
    "# 15 % reporting\n",
    "r15_3 = pd.read_csv(\"../partial_data/15/15_reporting.csv\")\n",
    "r15_6 = pd.read_csv(\"../partial_data/15/15_reporting_6.csv\")\n",
    "\n",
    "# 10 % reporting\n",
    "r10_3 = pd.read_csv(\"../partial_data/10/10_reporting.csv\")\n",
    "r10_6 = pd.read_csv(\"../partial_data/10/10_reporting_6.csv\")\n",
    "\n",
    "# 5 % reporting\n",
    "r5_3 = pd.read_csv(\"../partial_data/5/5_reporting.csv\")\n",
    "r5_6 = pd.read_csv(\"../partial_data/5/5_reporting_6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all of the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [r100_3, r100_6, r90_3, r90_6, r75_3, r75_6, r50_3, r50_6, \n",
    "               r25_3, r25_6, r15_3, r15_6, r10_3, r10_6, r5_3, r5_6]\n",
    "\n",
    "for d in data_frames:\n",
    "    d = encode(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize StratifiedKFold's to be set to 5 spilts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Six Strata\n",
    "\n",
    "Compare a Decision Tree with Correlations and 6 Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685959595959596 0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6.drop(columns=['WINNER'])\n",
    "y_ = r100_6.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 6 strata but no correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r100_6_nc = r100_6[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                         'S4_DEM_RATIO','S5_DEM_RATIO', 'S6_DEM_RATIO',\n",
    "                         'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                         'S4_REP_RATIO', 'S5_REP_RATIO', 'S6_REP_RATIO',\n",
    "                         'TIGHT_RACE', 'WINNER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7383838383838384 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 strata with correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731111111111111 0.65\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3.drop(columns=['WINNER'])\n",
    "y_ = r100_3.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 strata no correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r100_3_nc = r100_3[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                    'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                    'TIGHT_RACE', 'WINNER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7908080808080808 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(rf.score(X_test, y_test))\n",
    "    tight_from_test.append(rf.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085858585858585 0.85\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=7)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(dt.score(X_test, y_test))\n",
    "    tight_from_test.append(dt.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7572727272727272 0.75\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=7)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(dt.score(X_test, y_test))\n",
    "    tight_from_test.append(dt.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8118181818181818 0.9\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_6_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_6_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, max_depth=4)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(gbc.score(X_test, y_test))\n",
    "    tight_from_test.append(gbc.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7765656565656565 0.7\n"
     ]
    }
   ],
   "source": [
    "# for stratification - seperate the TIGHT_RACE\n",
    "X_over_s = r100_3_nc.drop(columns=['TIGHT_RACE'])\n",
    "y_over_s = r100_3_nc.TIGHT_RACE\n",
    "\n",
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER\n",
    "\n",
    "scores = []\n",
    "tight_from_test = []\n",
    "for train_index, test_index in skf.split(X_over_s, y_over_s):\n",
    "    X_test = X_.iloc[test_index]\n",
    "    y_test = y_.iloc[test_index]\n",
    "    \n",
    "    oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "    X = oversampled_df.drop(columns=['WINNER'])\n",
    "    y = oversampled_df.WINNER\n",
    "    \n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, max_depth=6)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(gbc.score(X_test, y_test))\n",
    "    tight_from_test.append(gbc.score(X_test[X_test.TIGHT_RACE], y_test[X_test.TIGHT_RACE]))\n",
    "    \n",
    "print(np.mean(scores), np.mean(tight_from_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
