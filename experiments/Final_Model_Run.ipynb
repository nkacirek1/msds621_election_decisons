{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    \"\"\"\n",
    "    Uses LabelEncoder to encode disrecete values\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            le = LabelEncoder()\n",
    "            df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data_f):\n",
    "    \"\"\"\n",
    "    Oversamples the highly contested races\n",
    "    \"\"\"\n",
    "    df_contested = data_f[data_f.TIGHT_RACE == True].reset_index(drop=True)\n",
    "    df_not_contested = data_f[data_f.TIGHT_RACE == False].reset_index(drop=True)\n",
    "    sample = np.random.choice(range(df_contested.shape[0]), size=df_not_contested.shape[0], replace=True)\n",
    "    df_contested_bootstrapped = df_contested.iloc[sample].reset_index(drop=True)\n",
    "    frames = [df_not_contested, df_contested_bootstrapped]\n",
    "    df_new = pd.concat(frames)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "- **r100** : 100% of precincts reporting\n",
    "- **r5**: 5% of precincts reporting\n",
    "- **_3**: 3 strata\n",
    "- **_6**: 6 strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 % reporting\n",
    "r100_3 = pd.read_csv(\"../full_data/final.csv\")\n",
    "r100_6 = pd.read_csv(\"../full_data/full_final.csv\")\n",
    "\n",
    "# 90 % reporting\n",
    "r90_3 = pd.read_csv(\"../partial_data/90/90_reporting.csv\")\n",
    "r90_6 = pd.read_csv(\"../partial_data/90/90_reporting_6.csv\")\n",
    "\n",
    "# 75 % reporting\n",
    "r75_3 = pd.read_csv(\"../partial_data/75/75_reporting.csv\")\n",
    "r75_6 = pd.read_csv(\"../partial_data/75/75_reporting_6.csv\")\n",
    "\n",
    "# 50 % reporting\n",
    "r50_3 = pd.read_csv(\"../partial_data/50/50_reporting.csv\")\n",
    "r50_6 = pd.read_csv(\"../partial_data/50/50_reporting_6.csv\")\n",
    "\n",
    "# 25 % reporting\n",
    "r25_3 = pd.read_csv(\"../partial_data/25/25_reporting.csv\")\n",
    "r25_6 = pd.read_csv(\"../partial_data/25/25_reporting_6.csv\")\n",
    "\n",
    "# 15 % reporting\n",
    "r15_3 = pd.read_csv(\"../partial_data/15/15_reporting.csv\")\n",
    "r15_6 = pd.read_csv(\"../partial_data/15/15_reporting_6.csv\")\n",
    "\n",
    "# 10 % reporting\n",
    "r10_3 = pd.read_csv(\"../partial_data/10/10_reporting.csv\")\n",
    "r10_6 = pd.read_csv(\"../partial_data/10/10_reporting_6.csv\")\n",
    "\n",
    "# 5 % reporting\n",
    "r5_3 = pd.read_csv(\"../partial_data/5/5_reporting.csv\")\n",
    "r5_6 = pd.read_csv(\"../partial_data/5/5_reporting_6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [r100_3, r100_6, r90_3, r90_6, r75_3, r75_6, r50_3, r50_6, \n",
    "               r25_3, r25_6, r15_3, r15_6, r10_3, r10_6, r5_3, r5_6]\n",
    "\n",
    "for d in data_frames:\n",
    "    d = encode(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "leave_one_out = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master list for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_plots = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the correlation\n",
    "r100_3_nc = r100_3[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                    'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                    'TIGHT_RACE', 'WINNER']]\n",
    "percents = [90, 75, 50, 25, 15, 10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_3_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_3_nc.WINNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dfs = [r90_3, r75_3, r50_3, r25_3, r15_3, r10_3, r5_3]\n",
    "testing_nc_dfs = [df[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                         'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                         'TIGHT_RACE', 'WINNER']] for df in testing_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(partial_reporting_df, perc):\n",
    "    scores = []\n",
    "    tight_from_test = []\n",
    "    p_scores = []\n",
    "    p_tight = []\n",
    "    \n",
    "    p_X = partial_reporting_df.drop(columns=['WINNER'])\n",
    "    p_y = partial_reporting_df.WINNER\n",
    "    p_tight_only = partial_reporting_df[partial_reporting_df.TIGHT_RACE]\n",
    "    p_tight_X = p_tight_only.drop(columns=['WINNER'])\n",
    "    p_tight_y = p_tight_only.WINNER\n",
    "    \n",
    "    for train_index, test_index in leave_one_out.split(X_):\n",
    "        X_test = X_.iloc[test_index]\n",
    "        y_test = y_.iloc[test_index]\n",
    "\n",
    "        oversampled_df = oversample(r100_3_nc.iloc[train_index])\n",
    "        X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "        y_train = oversampled_df.WINNER\n",
    "\n",
    "        dt = DecisionTreeClassifier(max_depth=6)\n",
    "        dt.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(dt.score(X_test, y_test))\n",
    "        if X_test.TIGHT_RACE.bool():\n",
    "            tight_from_test.append(dt.score(X_test, y_test))\n",
    "        p_scores.append(dt.score(p_X, p_y))\n",
    "        p_tight.append(dt.score(p_tight_X, p_tight_y))\n",
    "\n",
    "    print(np.mean(scores), np.mean(tight_from_test), np.mean(p_scores), np.mean(p_tight), perc)\n",
    "    return[scores, tight_from_test, p_scores, p_tight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334 0.7727272727272727 0.8588613013698629 0.7873079196217495 90\n",
      "0.8020833333333334 0.7727272727272727 0.8428938356164384 0.766044061302682 75\n",
      "0.7708333333333334 0.6363636363636364 0.8610159817351599 0.7830882352941176 50\n",
      "0.8229166666666666 0.7272727272727273 0.8518907563025211 0.7941080729166666 25\n",
      "0.8020833333333334 0.7727272727272727 0.8589750914076782 0.8049242424242425 15\n",
      "0.8125 0.7272727272727273 0.8379946727549467 0.7538496376811595 10\n",
      "0.7916666666666666 0.8181818181818182 0.8544883377135348 0.7864940068493151 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(percents)):\n",
    "    #decision_tree(testing_nc_dfs[i], percents[i])\n",
    "    for_plots.append(decision_tree(testing_nc_dfs[i], percents[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r100_6_nc = r100_6[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                         'S4_DEM_RATIO','S5_DEM_RATIO', 'S6_DEM_RATIO',\n",
    "                         'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                         'S4_REP_RATIO', 'S5_REP_RATIO', 'S6_REP_RATIO',\n",
    "                         'TIGHT_RACE', 'WINNER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dfs = [r90_6, r75_6, r50_6, r25_6, r15_6, r10_6, r5_6]\n",
    "testing_nc_dfs = [df[['S1_DEM_RATIO','S2_DEM_RATIO', 'S3_DEM_RATIO',\n",
    "                         'S4_DEM_RATIO','S5_DEM_RATIO', 'S6_DEM_RATIO',\n",
    "                         'S1_REP_RATIO', 'S2_REP_RATIO', 'S3_REP_RATIO',\n",
    "                         'S4_REP_RATIO', 'S5_REP_RATIO', 'S6_REP_RATIO',\n",
    "                         'TIGHT_RACE', 'WINNER']] for df in testing_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training - seperate the target (WINNER)\n",
    "X_ = r100_6_nc.drop(columns=['WINNER'])\n",
    "y_ = r100_6_nc.WINNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(partial_reporting_df, perc):\n",
    "    scores = []\n",
    "    tight_from_test = []\n",
    "    p_scores = []\n",
    "    p_tight = []\n",
    "    \n",
    "    p_X = partial_reporting_df.drop(columns=['WINNER'])\n",
    "    p_y = partial_reporting_df.WINNER\n",
    "    p_tight_only = partial_reporting_df[partial_reporting_df.TIGHT_RACE]\n",
    "    p_tight_X = p_tight_only.drop(columns=['WINNER'])\n",
    "    p_tight_y = p_tight_only.WINNER\n",
    "    \n",
    "    for train_index, test_index in leave_one_out.split(X_):\n",
    "        X_test = X_.iloc[test_index]\n",
    "        y_test = y_.iloc[test_index]\n",
    "\n",
    "        oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "        X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "        y_train = oversampled_df.WINNER\n",
    "\n",
    "        rf = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        if X_test.TIGHT_RACE.bool():\n",
    "            tight_from_test.append(rf.score(X_test, y_test))\n",
    "        p_scores.append(rf.score(p_X, p_y))\n",
    "        p_tight.append(rf.score(p_tight_X, p_tight_y))\n",
    "\n",
    "    print(np.mean(scores), np.mean(tight_from_test), np.mean(p_scores), np.mean(p_tight), perc)\n",
    "    return[scores, tight_from_test, p_scores, p_tight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8229166666666666 0.8181818181818182 0.9128710045662101 0.8481826241134752 90\n",
      "0.8020833333333334 0.7272727272727273 0.9040858066971079 0.8309386973180075 75\n",
      "0.84375 0.8181818181818182 0.9356449771689498 0.8805147058823531 50\n",
      "0.8125 0.6818181818181818 0.8995973389355743 0.8349880642361112 25\n",
      "0.8125 0.8181818181818182 0.9117058957952467 0.854914274322169 15\n",
      "0.8333333333333334 0.8181818181818182 0.9029680365296802 0.8299365942028984 10\n",
      "0.8333333333333334 0.7727272727272727 0.9046416447656593 0.8423944063926939 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(percents)):\n",
    "    #random_forest(testing_nc_dfs[i], percents[i])\n",
    "    for_plots.append(random_forest(testing_nc_dfs[i], percents[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_tree(partial_reporting_df, perc):\n",
    "    scores = []\n",
    "    tight_from_test = []\n",
    "    p_scores = []\n",
    "    p_tight = []\n",
    "    \n",
    "    p_X = partial_reporting_df.drop(columns=['WINNER'])\n",
    "    p_y = partial_reporting_df.WINNER\n",
    "    p_tight_only = partial_reporting_df[partial_reporting_df.TIGHT_RACE]\n",
    "    p_tight_X = p_tight_only.drop(columns=['WINNER'])\n",
    "    p_tight_y = p_tight_only.WINNER\n",
    "    \n",
    "    for train_index, test_index in leave_one_out.split(X_):\n",
    "        X_test = X_.iloc[test_index]\n",
    "        y_test = y_.iloc[test_index]\n",
    "\n",
    "        oversampled_df = oversample(r100_6_nc.iloc[train_index])\n",
    "        X_train = oversampled_df.drop(columns=['WINNER'])\n",
    "        y_train = oversampled_df.WINNER\n",
    "\n",
    "        gbt = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "        gbt.fit(X_train, y_train)\n",
    "        \n",
    "        scores.append(gbt.score(X_test, y_test))\n",
    "        if X_test.TIGHT_RACE.bool():\n",
    "            tight_from_test.append(gbt.score(X_test, y_test))\n",
    "        p_scores.append(gbt.score(p_X, p_y))\n",
    "        p_tight.append(gbt.score(p_tight_X, p_tight_y))\n",
    "\n",
    "    print(np.mean(scores), np.mean(tight_from_test), np.mean(p_scores), np.mean(p_tight), perc)\n",
    "    return [scores, tight_from_test, p_scores, p_tight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875 0.9090909090909091 0.9132705479452055 0.8532801418439718 90\n",
      "0.8541666666666666 0.9090909090909091 0.9058219178082192 0.8420737547892719 75\n",
      "0.8645833333333334 0.9090909090909091 0.9419235159817352 0.934436274509804 50\n",
      "0.875 0.9545454545454546 0.9027949415060142 0.8416883680555557 25\n",
      "0.8645833333333334 0.9090909090909091 0.9117439823278488 0.8600478468899522 15\n",
      "0.8854166666666666 0.9545454545454546 0.9083428462709283 0.8521286231884057 10\n",
      "0.8541666666666666 0.9090909090909091 0.907358738501971 0.8499928652968037 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(percents)):\n",
    "    #boost_tree(testing_nc_dfs[i], percents[i])\n",
    "    for_plots.append(boost_tree(testing_nc_dfs[i], percents[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_scores = for_plots[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = [g[0] for g in gbt_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675595238095238"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tight = [g[1] for g in gbt_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922077922077922"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
